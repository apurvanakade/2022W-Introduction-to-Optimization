# Geometry, Equivalence, Standard form {.unnumbered .unlisted}

## Using geometry to solve linear programs
Continuing Example \@ref(resource-allocation-problem), here is one way to see that (2, 2) is indeed the optimal solution. For any constant $c$, the equation 
\begin{equation}
  c = 25x + 30y
  (\#eq:objective-function)
\end{equation}
describes a line in $\mathbb{R}^2$. The points below this line have an objective value less than $c$ and the points above this line have an objective value greater than $c$. To see that $(2, 2)$ is the optimal solution, we simply need to check that the line of the form \@ref(eq:objective-function) that passes through $(2, 2)$, namely, $110 = 25x + 30y$ lies above the feasible region as seen in the following figure.

```{r, fig-resource-allocation-line, echo=FALSE, warning=FALSE, fig.cap="The feasible region lies below the line $110 = 25x + 30y$ and intersects it at $(2, 2)$."}

library(ggplot2)

ggplot() + 
  xlim(0, 200/25) +
  ylim(0, 200/20) +
  geom_vline(xintercept=c(0), alpha = 0.4) +
  geom_hline(yintercept=c(0), alpha = 0.4) +
  theme_bw() + 
  geom_polygon(
      data = data.frame(
        x = c(0, 0, 200/80, Inf),
        y = c(0, 200/20, 0, 0)),
      aes(x = x, y = y, fill = "1: 80x + 20y <= 200"),
      inherit.aes = FALSE, alpha = 0.4) + 
  geom_polygon(
      data = data.frame(
        x = c(0, 0, 200/25, Inf),
        y = c(0, 200/75, 0, 0)),
      aes(x = x, y = y, fill = "2: 25x + 75y <= 200"),
      inherit.aes = TRUE, alpha = 0.4) +
  scale_fill_discrete(name = "Constraints") +
  geom_point(aes(x=2, y=2), color = "black") +
  geom_text(aes(x=2, y=2), label="(2, 2)", vjust=-.5, hjust=0) +
  stat_function(fun = function(x) {(110 - 25*x)/30}, color = "black")
```

:::{.exercise}
Find an objective function $\zeta$ for which the point $(2, 2)$ is no longer an optimal solution.

:::

We can use the same reasoning to solve Exercise \@ref(exr:resource-allocation-problem-extra). Here, the linear program is:

```{r, latex-resource-allocation-extra, results = 'asis', echo = FALSE}
ex_1_1_lp <- new_linear_program(
  obj = c(25, 30),
  A = matrix(c(80, 20, 25, 75, 1, 1), nrow = 2, byrow = TRUE),
  b = c(200, 200, 3),
  variables = c('x', 'y')
)

cat(str_math(ex_1_1_lp))
```

The line of the form \@ref(eq:objective-function) for which the entire feasible region lies below it and which intersects the feasible region is $87.5 = 25x + 30y$ and it passes through $(0.5, 2.5)$. Here, instead of maximizing the time spend on each machine, we're maximizing the amount of resources produced and the time spent on the second machine $M_2$. As a result, our profit dropped from $110$ to $87.5$.

```{r, fig-resource-allocation-extra-line, echo=FALSE, warning=FALSE, fig.cap = "The feasible region lies below the line $87.5 = 25x + 30y$ and intersects it at $(0.5, 2.5)$."}

library(ggplot2)

ggplot() + 
  xlim(0, 200/25) +
  ylim(0, 200/20) +
  geom_vline(xintercept=c(0), alpha=0.4) +
  geom_hline(yintercept=c(0), alpha=0.4) +
  theme_bw() + 
  geom_polygon(
      data = data.frame(
        x = c(0, 0, 200/80, Inf),
        y = c(0, 200/20, 0, 0)),
      aes(x = x, y = y, fill = "1: 80x + 20y <= 200"),
      inherit.aes = FALSE, alpha = 0.4) + 
  geom_polygon(
      data = data.frame(
        x = c(0, 0, 200/25),
        y = c(0, 200/75, 0)),
      aes(x = x, y = y, fill = "2: 25x + 75y <= 200"),
      inherit.aes = TRUE, alpha = 0.4) +
  geom_polygon(
      data = data.frame(
        x = c(0, 0, 3),
        y = c(0, 3, 0)),
      aes(x = x, y = y, fill = "3: x + y <= 3"),
      inherit.aes = TRUE, alpha = 0.4) +
  scale_fill_discrete(name = "Constraints") + 
  stat_function(fun = function(x) {((0.5 * 25 + 2.5 * 30) - 25*x)/30}, color = "black") +
  geom_point(aes(x=0.5, y=2.5), color = "black") +
  geom_text(aes(x=0.5, y=2.5), label="(0.5, 2.5)", vjust=-.5, hjust=0)
```

In both the problems above, we simply found the line *by inspection*. There is no systematic way to do this using algebra! As a consequence, there is no way to create a useful algorithm out of this method. We'll see a completely new way of approaching this problem using the simplex method. 

## Equivalence of linear programs 

Before we get to the simplex method, we'll need to *standardize* our linear programs. 

The first step is to notice that every linear program can be changed to a *maximization problem* as minimizing a function $\zeta$ is the same as maximizing the function $-\zeta$.

> **From now on, we'll assume that the goal of our linear programs is to _maximize_ the objective function.**

Two (maximizing) linear programs LP and LP' are said to be *equivalent* if for any feasible solution $(x_1, \dots, x_n)$ to LP, there exists a feasible solution $(x'_1, x'_2, \dots, x'_{n'})$ to LP' with the same objective value \[ \zeta(x_1, \dots, x_n) = \zeta'(x'_1, x'_2, \dots, x'_{n'}), \] and vice versa. Thus solving LP is equivalent to LP'.

:::{.remark #lp-equiv-definition}

&nbsp;

1. LP and LP' can have a different number of decision variables i.e. we do not require $n = n'.$
2. There need not be a one-to-one correspondence between the feasible sets of LP and LP' i.e. for a feasible solution to LP there could be multiple feasible solutions with the same objective value. Similarly, in the other direction.

:::

:::{.remark}

Even though equivalence of linear programs only requires the existence of an abstract correspondence between the feasible sets of LP and LP', in practice, one constructs linear transformations $T: \mathbb{R}^n \to \mathbb{R}^{n'}$ and $S: \mathbb{R}^{n'} \to \mathbb{R}^{n}$ which map the feasible set of LP to LP' and the feasible set of LP' to LP, respectively. These linear transformations need not be inverses of each other, or even isomorphisms. However, they do need to preserve the objective values.

:::

<p class="todo"> Add examples here. </p>


## Standard form of linear programs

A linear program of the following form is said to be in a *standard form*:
\begin{equation}
  \begin{aligned}
    \mbox{maximize: } && c_1 x_1 + \dots + c_n x_n & \\
    \mbox{subject to: } 
      && a_{11} x_1 + \dots + a_{1n} x_n & \leq b_1 \\
      && a_{21} x_1 + \dots + a_{2n} x_n & \leq b_2 \\
      && \vdots &  \\
      && a_{m1} x_1 + \dots + a_{mn} x_n & \leq b_m \\
      && x_1, \dots, x_n & \geq 0.
  \end{aligned}
  (\#eq:intro-standardized-lp)
\end{equation}
Such a linear program can be written more succinctly using vectors and matrices as follows.
\begin{equation}
  \begin{aligned}
    \mbox{maximize: } && c^T x & \\
    \mbox{subject to: } 
      && A x & \leq b \\
      && x & \geq 0.
  \end{aligned}
  (\#eq:intro-standardized-lp-matrix-form)
\end{equation}
where $x$ is now the vector of decision variables, $c$ and $b$ are vectors of real numbers, and $A$ is the matrix of constraint coefficients. This enables us to use tools from Linear Algebra to solve linear programs.

<p class="todo"> Properties of the standard form.</p>

::: {.theorem #lp-to-standard-form}
Every linear program is equivalent to a linear program in the standard form.
:::

::: {.proof}
The proof is by explicit construction. Consider the linear program in \@ref(eq:intro-lp), where we're assuming that the goal is to maximize the objective function. If it is in the standard form, then we're done. If not, then there must be "errors" of the following forms:

1. A linear constraint is an upper bound and has the form $$a_{i1} x_1 + \dots + a_{in} x_n \geq b_i.$$
2. A linear constraint is an equality and has the form $$a_{i1} x_1 + \dots + a_{in} x_n = b_i.$$
3. A variable $x_j$ has a "negativity constraint" $x_j \leq 0$.
4. A variable $x_j$ is missing a "positivity constraint" $x_j \geq 0$.

**Case 1**: We multiply both sides by $-1$ giving us the constraint \[ -a_{i1} x_1 + \dots + -a_{in} x_n \leq -b_i. \]

**Case 2**: We replace $a_{i1} x_1 + \dots + a_{in} x_n = b_i$ with two inequalities
\begin{align*}
a_{i1} x_1 + \dots + a_{in} x_n &\leq b_i \\
a_{i1} x_1 + \dots + a_{in} x_n &\geq b_i
\end{align*}
which reduces the problem to Case 1.

**Case 3**: We let $y_j = -x_j$ and create a new linear program using the variables $x_1$, $\dots$, $x_{j-1}$, $y_j$, $x_{j+1}$, $\dots$, $x_n.$

**Case 4**: We let $x_j = x_j' - x_j''$ for two new decision variables $x_j'$ and $x_j''$ where $x_j', x_j'' \geq 0$. We can do this because any real number can written as a difference of two positive real numbers.

One can show that in each step the modified LP is equivalent to the original LP (Exercise \@ref(exr:lp-to-standard-form)).
:::

:::{.exercise #lp-to-standard-form}
Prove that the algorithm in the proof of Theorem \@ref(thm:lp-to-standard-form) produces a linear program that is equivalent to the original linear program.
:::
