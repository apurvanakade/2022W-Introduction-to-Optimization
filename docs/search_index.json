[["index.html", "Introduction to Optimization Preface", " Introduction to Optimization Apurva Nakade 2022-03-03 Preface The question of optimization is the very general question of deciding when a function \\(g(x_1, \\dots, x_n)\\) attains its maximum or minimum value on a domain \\(D\\) in \\(\\mathbb{R^n}\\). \\[\\begin{align} \\mbox{optimize: } &amp;&amp; g(x_1, \\dots, x_n) &amp; \\\\ \\mbox{subject to: } &amp;&amp; (x_1, \\dots, x_n) &amp;\\in D. \\end{align}\\] These questions show up frequently in every quantitative field. But it is almost impossible to analyze the question at this level of generality without making any further assumptions on \\(g\\) and \\(D\\). We will start with the simplest interesting functions, namely, linear functions. Well let \\(g\\) be a linear function and let \\(D\\) be a region cut out by linear (in)equalities. The study of this problem is called Linear Programming. Despite the simplicity of the Linear Programming setup, or perhaps because of it, LP is one of the most commonly used models for real world optimization problems. Most of this course is about Linear Programming. In the first half, well study the simplex method, which is an algorithm for solving linear programs, and in the second half well study the theory behind linear programs using duality theory. "],["introduction-to-linear-programming.html", "Lecture 1 Introduction to Linear Programming 1.1 Resource allocation problem", " Lecture 1 Introduction to Linear Programming Linear programming is a technique for the optimization of a linear objective function, subject to linear (in)equality constraints. A linear program or a linear programming problem is a problem of the following form: \\[\\begin{equation} \\begin{aligned} \\mbox{optimize: } &amp;&amp; c_1 x_1 + \\dots + c_n x_n &amp; \\\\ \\mbox{subject to: } &amp;&amp; a_{11} x_1 + \\dots + a_{1n} x_n &amp; \\ b_1 \\\\ &amp;&amp; a_{21} x_1 + \\dots + a_{2n} x_n &amp; \\lesseqqgtr b_2 \\\\ &amp;&amp; \\vdots &amp; \\\\ &amp;&amp; a_{m1} x_1 + \\dots + a_{mn} x_n &amp; \\lesseqqgtr b_m, \\end{aligned} \\tag{1.1} \\end{equation}\\] where the symbol \\(\\lesseqqgtr\\) stands for \\(\\leq\\) or \\(=\\) or \\(\\geq\\), \\(a_{ij}, b_i, c_j\\) are real numbers, and \\(x_j\\) are variables. The variables \\(x_1, \\dots, x_n\\) are called decision variables. The linear combination \\(\\zeta := c_1 x_1 + \\dots + c_n x_n\\) is called the objective function. Each of the (in)equalities \\(a_{i1} x_1 + \\dots + a_{in} x_n \\lesseqqgtr b_i\\) is called a (linear) constraint. Our goal is to either minimize or maximize the objective function subject to the constraints. A proposal of specific values for the decision variables is called a solution. A solution is said to be feasible if it satisfies all the constraints. A feasible solution is said to be optimal if \\(\\zeta\\) attains the optimal value at it. Thus, to solve a linear program means to find an optimal solution to the problem. If a problem has no feasible solutions, then the problem is called infeasible. If a problem has feasible solutions with arbitrarily large or arbitrary small objective values then the problem is called unbounded. Remark. We do not allow strict inequalities \\(&lt;\\) or \\(&gt;\\) in a linear program as linear functions do not always achieve maxima/minima on open sets. Consider the following simple example. \\[\\begin{align} \\mbox{maximize: }&amp;&amp; 10 x_1 &amp; \\\\ \\mbox{subject to: } &amp;&amp; 10 x_1 &amp; &lt; 20 \\\\ &amp;&amp; 5 x_1 &amp; \\geq 0\\end{align}\\] On the feasible set \\([0, 2)\\), the function \\(\\zeta(x_1) = 10x_1\\) never attains absolute maxima. Changing the inequality \\(&lt;\\) to \\(\\leq\\) gives us an optimal feasible solution \\(x_1 = 2\\) and \\(\\zeta = 20\\). When all the (in)equalities are either \\(\\le\\), \\(=\\), or \\(\\ge\\), the set of feasible solutions is closed. If, in addition, the LP is bounded then the set of feasible solutions is compact. On compact sets a continuous (in particular, linear) function, always attains a maxima and a minima by a generalization of the extreme value theorem for higher dimensions. 1.1 Resource allocation problem The following is an example of a resource allocation problem, a very common application of linear programming. The decision variables \\(x_j\\) denote the amount of a certain resource/product \\(j\\), the coefficients \\(c_j\\) are the profit per unit quantity of \\(j\\), and the constraints are certain upper bounds on the production of the resource/quantity. Example 1.1 You run a company that makes two products (say, \\(P_1\\) and \\(P_2\\)) using two machines (say, \\(M_1\\) and \\(M_2\\)). Each unit of \\(P_1\\) that is produced requires 80 minutes processing time on machine \\(M_1\\) and 25 minutes processing time on machine \\(M_2\\). Each unit of \\(P_2\\) that is produced requires 20 minutes processing time on machine \\(M_1\\) and 75 minutes processing time on machine \\(M_2\\). Both machines are available for a maximum of 200 minutes every day. The profit per unit of \\(P_1\\) is 25 units and the profit per unit of \\(P_2\\) is 30 units. Company policy is to determine the production quantity of each product in such a way as to maximize the total profit given that the available resources should not be exceeded. P1 P2 Upper_Bounds M1 80 20 200 M2 25 75 200 We can formulate the above problem as the following linear program. \\[\\begin{align} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; 25x &amp; + &amp; 30y \\\\ \\mbox{subject to: } &amp; 80x &amp; + &amp; 20y &amp; \\le &amp; 200 \\\\ &amp; 25x &amp; + &amp; 75y &amp; \\le &amp; 200 \\\\ \\end{array} \\\\ x, \\: y \\ge 0\\end{align}\\] Here \\(x\\), \\(y\\) are the units of \\(P_1\\) and \\(P_2\\) produced each day. One way to attempt this problem is to assume that well use both the machines as much as possible i.e.Â that the two inequalities are in fact equalities. We can see then that the common solution to the two is \\((x_1, x_2) = (2, 2)\\). For this solution the total profit is \\(110\\) units. Figure 1.1: The feasible region is the quadrilateral formed by the overlap of the constraints. Exercise 1.1 Why is this the maximum profit possible? Is it possible to increase the profit by not using either of the two machines at their full capacity? Exercise 1.2 Consider the setup in Example 1.1 again. Suppose in addition, you can only store a total of 3 units of \\(P_1\\) and \\(P_2\\) combined each day so your production quantity should not exceed that amount. What is the new LP and the new optimal solution? Note that the solution \\((x, y) = (2, 2)\\) is no longer possible. So, we cannot use both the machines to their maximum capacity. "],["geometry-equivalence-standard-form.html", "Lecture 2 Geometry, Equivalence, Standard form 2.1 Using geometry to solve linear programs 2.2 Equivalence of linear programs 2.3 Standard form of linear programs", " Lecture 2 Geometry, Equivalence, Standard form 2.1 Using geometry to solve linear programs Here is one way to see that \\((2, 2)\\) is the optimal solution to Example 1.1. For any constant \\(c\\), the equation \\[\\begin{equation} c = 25x + 30y \\tag{2.1} \\end{equation}\\] describes a line in \\(\\mathbb{R}^2\\). The points below this line have an objective value less than \\(c\\) and the points above this line have an objective value greater than \\(c\\). To see that \\((2, 2)\\) is the optimal solution, we simply need to see that the line of the form (2.1) that passes through it, namely \\(110 = 25x + 30y\\), lies above the feasible region as seen in the following figure. Figure 2.1: The feasible region lies below the line \\(110 = 25x + 30y\\) and intersects it at \\((2, 2)\\). Exercise 2.1 Find an objective function \\(\\zeta\\) for which the point \\((2, 2)\\) is no longer an optimal solution. We can use the same reasoning to solve Exercise 1.2, which is modelled by the following linear program. \\[\\begin{align} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; 25x &amp; + &amp; 30y \\\\ \\mbox{subject to: } &amp; 80x &amp; + &amp; 20y &amp; \\le &amp; 200 \\\\ &amp; 25x &amp; + &amp; 75y &amp; \\le &amp; 200 \\\\ &amp; 1x &amp; + &amp; 1y &amp; \\le &amp; 3 \\\\ \\end{array} \\\\ x, \\: y \\ge 0\\end{align}\\] The line of the form (2.1) for which the entire feasible region lies below it and which intersects the feasible region is \\(87.5 = 25x + 30y\\) and it passes through \\((0.5, 2.5)\\). Here, instead of maximizing the time spend on each machine, were maximizing the amount of resources produced and the time spent on the second machine \\(M_2\\). As a result, our profit dropped from \\(110\\) to \\(87.5\\). Figure 2.2: The feasible region lies below the line \\(87.5 = 25x + 30y\\) and intersects it at \\((0.5, 2.5)\\). In both the problems above, we found the line by inspection. There is no efficient way to do this purely algebraically! As a consequence, there is no way to create a useful algorithm out of this method. Well see a completely new way of approaching this problem using the simplex method. Instead of trying to find the optimal hyperplane, the simplex method jumps from vertex to vertex searching for the optimal solution. The existence of the optimal solution at a vertex is guaranteed by the following theorem. Theorem 2.1 Suppose the solution set of a linear program in two variables is non-empty and bounded. Then, The feasible set is a convex polygon. The optimal value is attained at a vertex of the feasible set. This theorem also holds in more than two variables, in which case instead of a convex polygon we get a convex polytope. The proof is in the following exercises. Exercise 2.2 Consider the following linear program \\[\\begin{align*} \\mbox{maximize: } &amp;&amp; c_1 x + c_2 y &amp; =: \\zeta(x,y) \\\\ \\mbox{subject to: } &amp;&amp; a_{11} x + a_{12} y &amp; \\lesseqqgtr b_1 \\\\ &amp;&amp; a_{21} x + a_{22} y &amp; \\lesseqqgtr b_2 \\\\ &amp;&amp; \\vdots &amp; \\\\ &amp;&amp; a_{m1} x + a_{m2} y &amp; \\lesseqqgtr b_m. \\end{align*}\\] Let \\(\\mathcal{S}\\) denote the feasible set. Assume that \\(\\mathcal{S}\\) is bounded and non-empty. Let \\(P = (x_1, y_1)\\) and \\(Q = (x_2, y_2)\\) be two distinct points in \\(\\mathbb{R}^2\\). Let \\(R = (x_3, y_3)\\) be a point lying on the line segment between \\(P\\) and \\(Q\\). Show that \\(R = tP + (1-t)Q\\) for some \\(t\\) in \\((0, 1)\\). Show that if that both \\(P\\) and \\(Q\\) satisfy the constraints above, then \\(R\\) also satisfies the constraints. Conclude that if \\(P\\) and \\(Q\\) are in \\(\\mathcal{S}\\) then so is \\(R\\). A subset of \\(\\mathbb{R}^n\\) is called convex if, given any two points in the subset, the subset contains the whole line segment that joins them. The above exercises show that \\(\\mathcal{S}\\) is a convex subset of \\(\\mathbb{R}^2\\). Furthermore, because it is bounded and defined using linear equations, it is a . Show that \\(\\zeta(R) = t\\zeta(P) + (1-t)\\zeta(Q)\\) for some \\(t\\) in $ (0,1) $. Show that either \\(\\zeta(R) \\le \\zeta(P)\\) or \\(\\zeta(R) \\le \\zeta(Q)\\) (or both). Let \\(R&#39;\\) be a point in the interior of \\(\\mathcal{S}\\). Argue that there is a point \\(P&#39;\\) on the boundary of \\(\\mathcal{S}\\) such that \\(\\zeta(R&#39;) \\le \\zeta(P&#39;)\\). Let \\(R&#39;&#39;\\) be a point in the interior of one of the edges of \\(\\mathcal{S}\\). Argue that there is a vertex \\(P&#39;&#39;\\) of \\(\\mathcal{S}\\) such that \\(\\zeta(R&#39;&#39;) \\le \\zeta(P&#39;&#39;)\\). Conclude that \\(\\zeta\\) attains its maximum value at a vertex of \\(\\mathcal{S}\\). 2.2 Equivalence of linear programs Before we get to the simplex method, well need to standardize our linear programs. The first step is to notice that every linear program can be changed to a maximization problem as minimizing a function \\(\\zeta\\) is the same as maximizing the function \\(-\\zeta\\). From now on, well assume that the goal of our linear programs is to maximize the objective function. Two (maximizing) linear programs LP and LP are said to be equivalent if for any feasible solution \\((x_1, \\dots, x_n)\\) to LP, there exists a feasible solution \\((x&#39;_1, x&#39;_2, \\dots, x&#39;_{n&#39;})\\) to LP with the same objective value \\[ \\zeta(x_1, \\dots, x_n) = \\zeta&#39;(x&#39;_1, x&#39;_2, \\dots, x&#39;_{n&#39;}), \\] and vice versa. Thus solving LP is equivalent to LP. Remark. Â  LP and LP can have a different number of decision variables i.e.Â we do not require \\(n = n&#39;.\\) There need not be a one-to-one correspondence between the feasible sets of LP and LP i.e.Â for a feasible solution to LP there could be multiple feasible solutions with the same objective value. Similarly, in the other direction. Remark. Even though equivalence of linear programs only requires the existence of an abstract correspondence between the feasible sets of LP and LP, in practice, one constructs linear transformations \\(T: \\mathbb{R}^n \\to \\mathbb{R}^{n&#39;}\\) and \\(S: \\mathbb{R}^{n&#39;} \\to \\mathbb{R}^{n}\\) which map the feasible set of LP to LP and the feasible set of LP to LP, respectively. These linear transformations need not be inverses of each other, or even isomorphisms. They only need to preserve the objective values. Example 2.1 The following linear programs are all equivalent to the linear program in Example 1.1. \\[\\begin{align} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; 250x &amp; + &amp; 300y \\\\ \\mbox{subject to: } &amp; 80x &amp; + &amp; 20y &amp; \\le &amp; 20 \\\\ &amp; 25x &amp; + &amp; 75y &amp; \\le &amp; 20 \\\\ \\end{array} \\\\ x, \\: y \\ge 0\\end{align}\\] \\[\\begin{align} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; 25x &amp; + &amp; 30y \\\\ \\mbox{subject to: } &amp; 800x &amp; + &amp; 200y &amp; \\le &amp; 2000 \\\\ &amp; 25x &amp; + &amp; 75y &amp; \\le &amp; 200 \\\\ \\end{array} \\\\ x, \\: y \\ge 0\\end{align}\\] \\[\\begin{align} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; 25x &amp; + &amp; 30y \\\\ \\mbox{subject to: } &amp; 80x &amp; + &amp; 20y &amp; \\le &amp; 200 \\\\ &amp; 25x &amp; + &amp; 75y &amp; \\le &amp; 200 \\\\ &amp; 2x &amp; + &amp; 2y &amp; \\le &amp; 200 \\\\ \\end{array} \\\\ x, \\: y \\ge 0\\end{align}\\] Example 2.2 The following two linear programs are equivalent to each other \\[\\begin{align*} \\begin{aligned} \\mbox{maximize: } &amp;&amp; x + y &amp; \\\\ \\mbox{subject to: } &amp;&amp; 0 \\le x &amp;\\le 1 \\\\ &amp;&amp; 0 \\le y &amp;\\le 1 \\end{aligned} &amp;&amp; \\begin{aligned} \\mbox{maximize: } &amp;&amp; z &amp; \\\\ \\mbox{subject to: } &amp;&amp; 0 \\le z &amp;\\le 1 \\end{aligned} \\end{align*}\\] via the transformations \\(T(x, y) = x + y\\) and \\(S(z) = (z/2, z/2)\\). 2.3 Standard form of linear programs A linear program of the following form is said to be in a standard form: \\[\\begin{equation} \\begin{array}{lrrrrrrrrr} \\mbox{maximize: } &amp; c_1 x_1 &amp; + &amp; \\dots &amp; + &amp; c_n x_n &amp; \\\\ \\mbox{subject to: } &amp; a_{11} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{1n} x_n &amp; \\leq &amp; b_1 \\\\ &amp; a_{21} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{2n} x_n &amp; \\leq &amp; b_2 \\\\ &amp; \\vdots &amp; \\\\ &amp; a_{m1} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{mn} x_n &amp; \\leq &amp; b_m \\end{array} \\\\ x_1, \\: \\dots \\: , \\: x_{n} \\: \\geq \\: 0 \\tag{2.2} \\end{equation}\\] Such a linear program can be written more succinctly using vectors and matrices as follows. \\[\\begin{equation} \\begin{aligned} \\mbox{maximize: } &amp;&amp; c^T x &amp; \\\\ \\mbox{subject to: } &amp;&amp; A x &amp; \\leq b \\\\ &amp;&amp; x &amp; \\geq 0. \\end{aligned} \\tag{2.3} \\end{equation}\\] where \\(x\\) is now the vector of decision variables, \\(c\\) and \\(b\\) are vectors of real numbers, and \\(A\\) is the matrix of constraint coefficients. This enables us to use tools from Linear Algebra to solve linear programs. Theorem 2.2 Every linear program is equivalent to a linear program in the standard form. Proof. The proof is by an explicit algorithm. Consider the linear program in (1.1), where were assuming that the goal is to maximize the objective function. If it is in the standard form, then were done. If not, then there must be a finite number of errors of the following types: A linear constraint is a lower bound and has the form \\[a_{i1} x_1 + \\dots + a_{in} x_n \\geq b_i.\\] A linear constraint is an equality and has the form \\[a_{i1} x_1 + \\dots + a_{in} x_n = b_i.\\] A variable \\(x_j\\) has a negativity constraint \\(x_j \\leq 0\\). A variable \\(x_j\\) is missing a sign constraint. We fix each error sequentially while making sure that no new errors are introduced, thereby ensuring termination of the algorithm. We replace the constraint with \\[ -a_{i1} x_1 + \\dots + -a_{in} x_n \\leq -b_i. \\] We replace the constraint with two constraints \\[\\begin{align*} a_{i1} x_1 + \\dots + a_{in} x_n &amp;\\leq b_i \\\\ -a_{i1} x_1 - \\dots - a_{in} x_n &amp;\\leq -b_i, \\end{align*}\\] We let \\(y_j = -x_j\\) and create a new linear program using the variables \\(x_1\\), \\(\\dots\\), \\(x_{j-1}\\), \\(y_j\\), \\(x_{j+1}\\), \\(\\dots\\), \\(x_n\\) by replacing \\(x_j\\) with \\(-y_j\\) everywhere. We let \\(x_j = y_j - z_j\\) for two new decision variables \\(y_j\\) and \\(z_j\\) with \\(y_j, z_j \\geq 0\\) and create a new linear program using the variables \\(x_1\\), \\(\\dots\\), \\(x_{j-1}\\), \\(y_j\\), \\(z_j\\), \\(x_{j+1}\\), \\(\\dots\\), \\(x_n\\) by replacing \\(x_j\\) with \\(y_j - z_j\\) everywhere. We can do this because any real number can written as a difference of two positive real numbers. One can show that in each step the modified LP is equivalent to the original LP. Exercise 2.3 Prove that the algorithm in the proof of Theorem 2.2 produces a linear program that is equivalent to the original linear program. "],["simplex-method---example.html", "Lecture 3 Simplex Method - Example", " Lecture 3 Simplex Method - Example The simplex method jumps from vertex of the feasible region to find the optimal solution. It is best demonstrated using an example. Consider the following linear program. \\[\\begin{equation} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; 1x_1 &amp; + &amp; 1.5x_2 \\\\ \\mbox{subject to: } &amp; 1x_1 &amp; + &amp; 2x_2 &amp; \\le &amp; 10 \\\\ &amp; 4x_1 &amp; + &amp; 3x_2 &amp; \\le &amp; 20 \\\\ \\end{array} \\\\ x_1, \\: x_2 \\ge 0 \\tag{3.1} \\end{equation}\\] The optimal solution is \\((x_1, x_2) = (2, 4)\\) with objective value \\(6\\). There are six different points at which the lines corresponding to the constraints intersect. Well start with the vertex \\((0,0)\\) and make our way up to \\((2, 4)\\) while making sure that we do not leave the feasible region. The first, and arguably the most important trick in the simplex algorithm is the introduction of slack variables \\(x_3\\) and \\(x_4\\), one for each constraint, as shown below, to create a new linear program called a dictionary which is equivalent to (3.1) \\[\\begin{equation} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; \\zeta &amp;=&amp;0&amp; + &amp;1x_1 &amp;+&amp; 1.5x_2 \\\\ \\mbox{subject to: } &amp; x_3 &amp; = &amp; 10 &amp; - &amp;1x_1 &amp; - &amp;2x_2 \\\\ &amp; x_4 &amp; = &amp; 20 &amp; - &amp;4x_1 &amp; - &amp;3x_2 \\\\ \\end{array} \\\\ x_1, \\: x_2, \\: x_3, \\: x_4 \\ge 0 \\tag{3.2} \\end{equation}\\] Using these new variables, the points of intersection can be written as intersections of the lines \\(x_i = 0\\) and \\(x_j = 0\\), as \\(i\\) and \\(j\\) vary over the index set \\(\\{1, 2, 3, 4\\}\\). And so to traverse the set of vertices, we simply need to traverse the two element subsets of \\(\\{x_1 = 0, x_2 = 0, x_3 = 0, x_4 = 0\\}\\). We start with the guess: \\(x_1 = 0, x_2 = 0, x_3 = 10, x_4 = 20\\). At this point, \\(\\zeta = 0\\). We can increase \\(\\zeta\\) by increasing either \\(x_1\\) or \\(x_2\\). Lets choose \\(x_1\\) and leave \\(x_2\\) fixed at \\(0\\). To not violate the positivity of \\(x_3\\), \\(x_4\\), we can only increase \\(x_1\\) enough that both \\(10 \\ge x_1\\) and \\(20 \\ge 4x_1\\) remain true. The maximum such \\(x_1\\) is \\(5\\) and this makes \\(x_4 = 0\\). We rewrite \\(x_1\\), \\(x_3\\), and \\(\\zeta\\) in terms of the new variables that are \\(0\\), namely \\(x_2\\) and \\(x_4\\), to create a new dictionary: \\[\\begin{equation} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; \\zeta &amp;=&amp;5&amp; + &amp;-0.25x_4 &amp;+&amp; 0.75x_2 \\\\ \\mbox{subject to: } &amp; x_3 &amp; = &amp; 5 &amp; - &amp;-0.25x_4 &amp; - &amp;1.25x_2 \\\\ &amp; x_1 &amp; = &amp; 5 &amp; - &amp;0.25x_4 &amp; - &amp;0.75x_2 \\\\ \\end{array} \\\\ x_4, \\: x_2, \\: x_3, \\: x_1 \\ge 0 \\tag{3.3} \\end{equation}\\] Our new guess is: \\(x_1 = 5, x_2 = 0, x_3 = 5, x_4 = 0\\). The coefficient of \\(x_4\\) in the objective function is negative. Increasing it will only decrease the objective value. The only variable we can increase in the objective function is \\(x_2\\). To not violate the positivity of \\(x_1\\), \\(x_3\\), we can only increase \\(x_2\\) enough that both \\(5 \\ge 1.25x_2\\) and \\(5 \\ge 0.75x_2\\) remain true. The maximum such \\(x_2\\) is \\(\\min(5/1.25, 5/0.75) = 5/1.25 = 4\\) and this makes \\(x_3 = 0\\). We rewrite \\(x_2\\), \\(x_1\\), and \\(\\zeta\\) in terms of the new variables that are \\(0\\), namely \\(x_3\\) and \\(x_4\\), to create a new dictionary: \\[\\begin{equation} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; \\zeta &amp;=&amp;8&amp; + &amp;-0.1x_4 &amp;+&amp; -0.6x_3 \\\\ \\mbox{subject to: } &amp; x_2 &amp; = &amp; 4 &amp; - &amp;-0.2x_4 &amp; - &amp;0.8x_3 \\\\ &amp; x_1 &amp; = &amp; 2 &amp; - &amp;0.4x_4 &amp; - &amp;-0.6x_3 \\\\ \\end{array} \\\\ x_4, \\: x_3, \\: x_2, \\: x_1 \\ge 0 \\tag{3.4} \\end{equation}\\] Our new guess is: \\(x_1 = 2, x_2 = 4, x_3 = 0, x_4 = 0\\). The coefficients of both the variables that appear in \\(\\zeta\\) are negative. It is not possible to increase either variable without decreasing the objective value. The simplex algorithm halts. The optimal objective value \\(8\\) is the constant coefficient in the final \\(\\zeta\\) and it is attained at \\((x_1, x_2) = (2, 4)\\). "],["two-phase-simplex-method.html", "Lecture 4 Two-Phase Simplex Method 4.1 Phase II 4.2 Phase I", " Lecture 4 Two-Phase Simplex Method As we saw in Example (3.1), the two phase simplex method is an algorithm for solving a linear program in the standard form. The method described below is the Two phase simplex method using the dictionary notation. Well later see an implementation of the same method using the tableaux notation. Given a standard linear program (2.2), we can form an linear program, called a dictionary, of the following form by introducing slack variables \\(x_{n+1}, \\dots, x_{n + m}\\). \\[\\begin{equation} \\begin{array}{rrrrrrrrrrrr} \\mbox{maximize: } &amp; \\zeta &amp; = &amp; c _ 0 &amp; + &amp; c_1 x_1 &amp; + &amp; \\dots &amp; + &amp; c_n x_n \\\\ \\mbox{subject to: } &amp; x_{n+1} &amp; = &amp; b_1 &amp; - &amp; a_{11} x_1 &amp; - &amp; \\dots &amp; - &amp; a_{1n} x_n \\\\ &amp; x_{n+2} &amp; = &amp; b_2 &amp; - &amp; a_{21} x_1 &amp; - &amp; \\dots &amp; - &amp; a_{2n} x_n \\\\ &amp; &amp; &amp; &amp; &amp; &amp; \\vdots &amp; &amp; \\\\ &amp; x_{n+m} &amp; = &amp; b_m &amp; - &amp; a_{m1} x_1 &amp; - &amp; \\dots &amp; - &amp; a_{mn} x_n, \\end{array} \\\\ x_1, \\: \\dots \\: , \\: x_{m + n} \\: \\geq \\: 0. \\tag{4.1} \\end{equation}\\] The variables appearing on the right-hand side are called non-basic variables, and the variables appearing on the left-hand side are called basic variables. The simplex algorithm creates a sequence of dictionaries through a process called pivoting. In each pivot step, one non-basic variable becomes basic; this is the entering variable, and one basic variable becomes non-basic; this is the leaving variable. A basic solution of the dictionary is obtained by setting all the non-basic variables to 0. If such a solution is feasible, then it is called a basic feasible solution (BFS for short). In this case, we say that the dictionary is feasible. Exercise 4.1 Show that a dictionary is feasible if and only if all the constants \\(b_i\\) are non-negative. 4.1 Phase II Phase II of the simplex method assumes that the dictionary is feasible. If this is not the case, we use Phase I to try and find a feasible dictionary. Once we have a feasible dictionary, we proceed as follows. Find the entering variable: Let \\(e\\) be an index such that \\(c_e\\) is positive. If none exists, exit. Find the leaving variable: Let \\(S\\) be the set of indices \\(i\\) such that \\(a_{ie}\\) is positive. Set \\(\\ell = \\mathrm{arg}\\min_{i \\in S} \\left(\\dfrac{b_i}{a_{ie}}\\right)\\). Pivot: Add \\(x_e\\) to the set of basic variables and remove it from the set of non-basic variables. Add \\(x_\\ell\\) to the set of non-basic variables and remove it from the set of basic variables. Rewrite the basic variables and the objective function in terms of the non-basic variables. Go back to step 1. Assuming the program halts, the optimal solution will be the BFS of the final dictionary. 4.2 Phase I In the case when some of the constants \\(b_i\\) are negative, Phase I of the simplex algorithm is used to find a feasible dictionary. It attempts to find a sequence of pivots on the dictionary (4.1) that make it feasible. The trick is to create the following auxiliary linear program whose optimal solution provides a BFS of the original linear program, if one exists. \\[\\begin{equation} \\begin{array}{rrrrrrrrrrrr} \\mbox{maximize: } &amp; &amp; &amp; &amp; &amp; &amp; - &amp; x_0 \\\\ \\mbox{subject to: } &amp; a_{11} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{1n} x_n &amp; - &amp; x_0 &amp; \\le &amp; b_1 \\\\ &amp; a_{21} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{2n} x_n &amp; - &amp;x_0 &amp; \\le &amp; b_2 \\\\ &amp; &amp; &amp; &amp; &amp; &amp; \\vdots &amp; &amp; \\\\ &amp; a_{m1} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{mn} x_n &amp; - &amp;x_0 &amp; \\le &amp; b_m \\end{array} \\\\ x_0, \\: x_1, \\: \\dots \\: , \\: x_{n} \\: \\geq \\: 0 \\tag{4.2} \\end{equation}\\] We create an (infeasible) dictionary for this linear program and process as follows. Find leaving variable: Set \\(\\ell = \\mathrm{arg}\\min_{1 \\le i \\le m} b_i\\). Pivot: Add \\(x_0\\) to the set of basic variables and remove it from the set of non-basic variables. Add \\(x_\\ell\\) to the set of non-basic variables and remove it from the set of basic variables. Rewrite the basic variables and the objective function in terms of the non-basic variables. Solve: Apply the Phase II algorithm to find an optimal solution. Phase II: In the optimal solution, If \\(x_0 \\neq 0\\), then the original linear program is not feasible. If \\(x_0 = 0\\), Form the initial infeasible dictionary from the original linear program. Perform pivots until the optimal solution of the auxiliary linear program becomes the BFS of the resulting dictionary. Proceed to Phase II. Step 2 of the above algorithm creates a feasible dictionary by Exercise 4.3. Hence, we can use the Phase II algorithm to solve the auxiliary linear program in Step 3. The solution obtained in Step 3 provides a BFS of the original linear program when \\(x_0 = 0\\) by the proof of Part 4 of Exercise 4.2. Exercise 4.2 The following exercises prove that optimal solution of the auxiliary linear program provides a BFS of the original linear program. Show that the linear program (4.2) is always feasible. Assume that the linear program (4.2) always has an optimal solution. Show that the optimal objective value of (4.2) is always \\(\\le 0\\). Show that if the linear program (2.2) is feasible then the optimal objective value of (4.2) is 0. Show that if the optimal objective value of (4.2) is 0 then (2.2) is feasible. Exercise 4.3 Suppose the dictionary of (2.2) (and hence (4.2)) is not feasible. Without any loss of generality, assume that \\(b_1\\) is the smallest among all the \\(b_i\\) (i.e.Â the most negative). Show that the initial dictionary of (4.2) becomes feasible after one pivot step that makes \\(x_0\\) basic and \\(x_{n+1}\\) non-basic. "],["phase-i---example-unboundedness.html", "Lecture 5 Phase I - Example, Unboundedness 5.1 Phase I - Example 5.2 Unboundedness", " Lecture 5 Phase I - Example, Unboundedness 5.1 Phase I - Example Consider the following linear program: \\[\\begin{align} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; -2x_1 &amp; + &amp; -1x_2 \\\\ \\mbox{subject to: } &amp; -1x_1 &amp; + &amp; 1x_2 &amp; \\le &amp; -1 \\\\ &amp; -1x_1 &amp; + &amp; -2x_2 &amp; \\le &amp; -2 \\\\ &amp; 0x_1 &amp; + &amp; 1x_2 &amp; \\le &amp; 1 \\\\ \\end{array} \\\\ x_1, \\: x_2 \\ge 0\\end{align}\\] The initial dictionary formed using this linear program is not feasible because \\(b_1, b_2 &lt; 0\\). So, we initiate Phase I to find a feasible dictionary first. The first step is to create an auxiliary linear program and form its dictionary (which is still infeasible). \\[\\begin{align} \\begin{array}{rrrrrrrrrr} \\mbox{maximize: } &amp; \\zeta &amp;=&amp;0&amp; + &amp;0x_1 &amp;+&amp; 0x_2 &amp;+&amp; -1x_0 \\\\ \\mbox{subject to: } &amp; x_3 &amp; = &amp; -1 &amp; - &amp;-1x_1 &amp; - &amp;1x_2 &amp; - &amp;-1x_0 \\\\ &amp; x_4 &amp; = &amp; -2 &amp; - &amp;-1x_1 &amp; - &amp;-2x_2 &amp; - &amp;-1x_0 \\\\ &amp; x_5 &amp; = &amp; 1 &amp; - &amp;0x_1 &amp; - &amp;1x_2 &amp; - &amp;-1x_0 \\\\ \\end{array} \\\\ x_1, \\: x_2, \\: x_0, \\: x_3, \\: x_4, \\: x_5 \\ge 0\\end{align}\\] The most negative \\(b_i\\) is \\(b_2 = -2\\). So we perform a pivot that makes \\(x_0\\) entering and \\(x_4\\) leaving. This updates our dictionary to the following. \\[\\begin{align} \\begin{array}{rrrrrrrrrr} \\mbox{maximize: } &amp; \\zeta &amp;=&amp;-2&amp; + &amp;1x_1 &amp;+&amp; -2x_2 &amp;+&amp; -1x_4 \\\\ \\mbox{subject to: } &amp; x_3 &amp; = &amp; 1 &amp; - &amp;0x_1 &amp; - &amp;-1x_2 &amp; - &amp;-1x_4 \\\\ &amp; x_0 &amp; = &amp; 2 &amp; - &amp;1x_1 &amp; - &amp;-2x_2 &amp; - &amp;-1x_4 \\\\ &amp; x_5 &amp; = &amp; 3 &amp; - &amp;1x_1 &amp; - &amp;-1x_2 &amp; - &amp;-1x_4 \\\\ \\end{array} \\\\ x_1, \\: x_2, \\: x_4, \\: x_3, \\: x_0, \\: x_5 \\ge 0\\end{align}\\] We solve this using the Phase II simplex method to get the following final feasible dictionary and an optimal solution \\(x_1 = 2, {\\color{red}{x_2 = 0}}, x_3 = 1, {\\color{red}{x_4 = 0}}, x_5 = 1\\). After this, we go back to the original linear program and form its initial (infeasible) dictionary. \\[\\begin{align} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; \\zeta &amp;=&amp;0&amp; + &amp;-2x_1 &amp;+&amp; -1x_2 \\\\ \\mbox{subject to: } &amp; x_3 &amp; = &amp; -1 &amp; - &amp;-1x_1 &amp; - &amp;1x_2 \\\\ &amp; x_4 &amp; = &amp; -2 &amp; - &amp;-1x_1 &amp; - &amp;-2x_2 \\\\ &amp; x_5 &amp; = &amp; 1 &amp; - &amp;0x_1 &amp; - &amp;1x_2 \\\\ \\end{array} \\\\ x_1, \\: x_2, \\: x_3, \\: x_4, \\: x_5 \\ge 0\\end{align}\\] The current non-basic variables are \\(x_1\\), \\(x_2\\) but the solution to the auxiliary linear program tells us that the non-basic variables need to be \\(x_2\\) and \\(x_4\\) to get a feasible dictionary. So, we perform a pivot that make \\(x_1\\) enter and \\(x_4\\) leave the set of basic variables to get the following feasible dictionary. \\[\\begin{align} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; \\zeta &amp;=&amp;-4&amp; + &amp;-2x_4 &amp;+&amp; 3x_2 \\\\ \\mbox{subject to: } &amp; x_3 &amp; = &amp; 1 &amp; - &amp;-1x_4 &amp; - &amp;3x_2 \\\\ &amp; x_1 &amp; = &amp; 2 &amp; - &amp;-1x_4 &amp; - &amp;2x_2 \\\\ &amp; x_5 &amp; = &amp; 1 &amp; - &amp;0x_4 &amp; - &amp;1x_2 \\\\ \\end{array} \\\\ x_4, \\: x_2, \\: x_3, \\: x_1, \\: x_5 \\ge 0\\end{align}\\] This dictionary is now feasible and can be solved using the Phase II of the simplex method to get the optimal solution \\(x_1 = 1/3, x_2 = 4/3, \\zeta = -3\\). 5.2 Unboundedness In the Phase II, we find the leaving variable by comparing the constants \\(b_i/a_{ie}\\) where the index \\(i\\) varies over all the positive \\(a_{ie}\\). However, it can happen that none of the \\(a_{ie}\\) are positive. In this case, the entering variable \\(x_e\\) can be made arbitrarily large while still maintaining all the positive constraints and the objective can become arbitrarily large i.e.Â the linear program is unbounded with no largest optimal value. The updated Phase II algorithm is as follows. Find the entering variable: Let \\(e\\) be an index such that \\(c_e\\) is positive. If none exists, exit. Find the leaving variable: Let \\(S\\) be the set of indices \\(i\\) such that \\(a_{ie}\\) is positive. If \\(S\\) is empty, exit. Linear program is unbounded with no optimal solution. Set \\(\\ell = \\mathrm{arg}\\min_{i \\in S} \\left(\\dfrac{b_i}{a_{ie}}\\right)\\). Pivot: Add \\(x_e\\) to the set of basic variables and remove it from the set of non-basic variables. Add \\(x_\\ell\\) to the set of non-basic variables and remove it from the set of basic variables. Rewrite the basic variables and the objective function in terms of the non-basic variables. Go back to step 1. "],["blands-rule-kleeminty-cube.html", "Lecture 6 Blands rule, KleeMinty cube 6.1 Blands rule 6.2 KleeMinty cube", " Lecture 6 Blands rule, KleeMinty cube 6.1 Blands rule A pivot where \\(x_e\\) enters and \\(x_\\ell\\) leaves is said to be degenerate if \\(a_{\\ell e} &gt; 0\\) and \\(b_\\ell = 0\\). In this case, as \\(b_{\\ell}/a_{\\ell e}\\), the entering variables value remains unchanged at 0 even after it becomes basic. Similarly, the objective value also stays constant after the pivot. Degenerate simplices can cause the simplex algorithm to get stuck in an infinite loop. In linear programming, this issue is called cycling. For example, the following linear program \\[\\begin{align} \\begin{array}{rrrrrrrrrrrr} \\mbox{maximize: } &amp; 1x_1 &amp; + &amp; -2x_2 &amp; + &amp; 0x_3 &amp; + &amp; -2x_4 \\\\ \\mbox{subject to: } &amp; 0.5x_1 &amp; + &amp; -3.5x_2 &amp; + &amp; -2x_3 &amp; + &amp; 4x_4 &amp; \\le &amp; 0 \\\\ &amp; 0.5x_1 &amp; + &amp; -1x_2 &amp; + &amp; -0.5x_3 &amp; + &amp; 0.5x_4 &amp; \\le &amp; 0 \\\\ &amp; 1x_1 &amp; + &amp; 0x_2 &amp; + &amp; 0x_3 &amp; + &amp; 0x_4 &amp; \\le &amp; 1 \\\\ \\end{array} \\\\ x_1, \\: x_2, \\: x_3, \\: x_4 \\ge 0\\end{align}\\] cycles for the following pivot rules: \\(x_1\\) enters and \\(x_5\\) leaves, \\(x_2\\) enters and \\(x_6\\) leaves, \\(x_3\\) enters and \\(x_1\\) leaves, \\(x_4\\) enters and \\(x_2\\) leaves, \\(x_5\\) enters and \\(x_3\\) leaves, \\(x_6\\) enters and \\(x_4\\) leaves. There are several ways to prevent cycling, the simplest of which is called Blands rule, which states that whenever there are multiple candidates for the entering or leaving variables, choose the one with the smallest index. One can check that the sixth pivot in the above example violates Blands rule. Theorem 6.1 Blands rule prevent cycling. The updated Phase II simplex algorithm that takes into account Blands rule is as follows. Find the entering variable: Let \\(E\\) be the set of indices \\(j\\) such that \\(c_{j}\\) is positive. If \\(E\\) is empty, exit. Set \\(e = \\min E\\). Find the leaving variable: Let \\(L\\) be the set of indices \\(i\\) such that \\(a_{ie}\\) is positive. If \\(L\\) is empty, exit. Linear program is unbounded with no optimal solution. Set \\(\\ell = \\min \\left[ \\mathrm{arg}\\min_{i \\in L} \\left(\\dfrac{b_i}{a_{ie}}\\right) \\right]\\). Pivot: Add \\(x_e\\) to the set of basic variables and remove it from the set of non-basic variables. Add \\(x_\\ell\\) to the set of non-basic variables and remove it from the set of basic variables. Rewrite the basic variables and the objective function in terms of the non-basic variables. Go back to step 1. 6.2 KleeMinty cube The simplex algorithm runs in polynomial time over real-world problems but is an exponential time algorithm in the worst case. The following is an example of a linear program in \\(n\\) variables and \\(n\\) constraints, called a KleeMinty cube, for which the simplex method requires \\(\\mathcal{O}(2^n)\\) steps. One proves this by showing that the feasible set has \\(2^n\\) vertices and the simplex algorithm visits all the vertices of the feasible set. \\[\\begin{align} \\begin{array}{rlllllllll} \\mbox{maximize: } &amp; \\sum \\limits_{j = 1}^n x_j &amp; \\\\ \\mbox{subject to: } &amp; \\sum \\limits_{j = 1}^{i - 1} 2 x_j + x_i &amp; \\le 2^{i - 1} &amp; &amp; \\mbox{ for } i = 1, \\dots, n. \\end{array} \\end{align}\\] "],["introduction-to-duality.html", "Lecture 7 Introduction to Duality 7.1 Dual Linear Program 7.2 Shadow Prices", " Lecture 7 Introduction to Duality 7.1 Dual Linear Program Let us consider the linear program (3.1) again. \\[\\begin{equation} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; 1x_1 &amp; + &amp; 1.5x_2 \\\\ \\mbox{subject to: } &amp; 1x_1 &amp; + &amp; 2x_2 &amp; \\le &amp; 10 \\\\ &amp; 4x_1 &amp; + &amp; 3x_2 &amp; \\le &amp; 20 \\\\ \\end{array} \\\\ x_1, \\: x_2 \\ge 0 \\tag{7.1} \\end{equation}\\] We can interpret this as a resource allocation problem where were producing two products \\(P_1\\) and \\(P_2\\) using machines \\(M_1\\) and \\(M_2\\). Each product requires some time on each of the machines, and each constraint represents the total time available on each machine. P1 P2 Upper_Bounds M1 1 2 10 M2 4 3 20 Now, we consider the following dual question. Suppose were interested in renting out the machines. What is the minimum price can we can rent out the machines so that, for each product, the profit from renting is at least as much as the profit from producing? If this is not the case, then it is more profitable to produce than rent out. Suppose we rent out \\(M_1\\) and \\(M_2\\) at the rate of \\(y_1\\) and \\(y_2\\) per hour, respectively. Suppose further that we only rent \\(M_1\\) for 10 hours and \\(M_2\\) for 20 hours as a package. Then the following inequalities must hold: \\[\\begin{align} y_1 + 4y_2 &amp; \\ge 1 \\\\ 2y_1 + 3y_2 &amp; \\ge 1.5 \\end{align}\\] where we can interpret \\(y_1 + 4y_2\\) and \\(2y_1 + 3y_2\\) as the calculated price from the production of \\(P_1\\) and \\(P_2.\\) The inequalities say that, for each product, the calculated price from renting is at least as much as the price from selling the product directly. Given these constraints, we then ask the minimum total profit we can make from renting. This gives us the following dual linear program. (The original linear program (7.1) is called the primal.) \\[\\begin{equation} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; 10y_1 &amp; + &amp; 20y_2 \\\\ \\mbox{subject to: } &amp; 1y_1 &amp; + &amp; 4y_2 &amp; \\le &amp; 1 \\\\ &amp; 2y_1 &amp; + &amp; 3y_2 &amp; \\le &amp; 1.5 \\\\ \\end{array} \\\\ y_1, \\: y_2 \\ge 0 \\tag{7.2} \\end{equation}\\] We can solve this geometrically, to get the optimal solution \\((y_1, y_2) = (0.6, 0.1)\\) and the objective value \\(8\\). It is not a coincidence that the optimal objective value of the dual is the same as the optimal objective value of the primal. This is a consequence of strong duality. Figure 7.1: The feasible region is the unbounded non-shaded region, as the inequalities are reversed. The entire feasible region lies above line 8 = 10y_1 + 20y_2. 7.2 Shadow Prices For a linear program in the standard form, the shadow price of the constraint \\(b_i\\) is defined as the increase in the value of the optimal objective value per unit increase in the constraint \\(b_i\\), while keeping everything else constant. If we think of the constraints as limits on our production capacity, then the shadow price is the increase in maximum profit per unit increase in production capacity. Alternately, shadow prices are the expenses we can afford for increasing the production capacities without incurring any losses. More precisely, the shadow price of the \\(i^{th}\\) constraint is simply \\[\\begin{align} \\dfrac{\\partial \\zeta_\\max}{\\partial b_i}. \\end{align}\\] Because all our equations are linear, we can calculate shadow prices by making a small change in \\(b_i\\) i.e. \\[\\begin{equation} \\dfrac{\\partial \\zeta_\\max}{\\partial b_i} = \\dfrac{\\Delta \\zeta_\\max}{\\Delta b_i}. \\tag{7.3} \\end{equation}\\] where \\(\\Delta \\zeta\\) is increase in the optimal objective value when \\(b_i\\) is increased to \\(b_i + \\Delta b_i\\). Remark. While using the approximation (7.3) it is important to keep the change \\(\\Delta b_i\\) small. We want the perturbed feasible set to be close to the original feasible set. No new vertices should be created and no existing vertices should be deleted by the perturbation. For example, to calculate the shadow prices for (7.1) we can solve the following linear programs. \\[\\begin{align} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; 1x_1 &amp; + &amp; 1.5x_2 \\\\ \\mbox{subject to: } &amp; 1x_1 &amp; + &amp; 2x_2 &amp; \\le &amp; 10.1 \\\\ &amp; 4x_1 &amp; + &amp; 3x_2 &amp; \\le &amp; 20 \\\\ \\end{array} \\\\ x_1, \\: x_2 \\ge 0\\end{align}\\] \\[\\begin{align} \\begin{array}{rrrrrrrr} \\mbox{maximize: } &amp; 1x_1 &amp; + &amp; 1.5x_2 \\\\ \\mbox{subject to: } &amp; 1x_1 &amp; + &amp; 2x_2 &amp; \\le &amp; 10 \\\\ &amp; 4x_1 &amp; + &amp; 3x_2 &amp; \\le &amp; 20.1 \\\\ \\end{array} \\\\ x_1, \\: x_2 \\ge 0\\end{align}\\] The optimal objective value of the first linear program is \\(8.06\\) so the shadow price for the first constraint is \\(\\dfrac{8.06 - 8}{0.1} = 0.6\\). The optimal objective value of the second linear program is \\(8.01\\) so the shadow price for the first constraint is \\(\\dfrac{8.01 - 8}{0.1} = 0.1\\). These values are precisely the optimal solutions to the dual linear program! This provides another interpretation of the dual linear program as calculating the shadow prices of the primal. "],["weak-duality.html", "Lecture 8 Weak Duality 8.1 Certificate of Optimality", " Lecture 8 Weak Duality The dual of the standard linear program (2.3) is the the following \\[\\begin{equation} \\begin{aligned} \\mbox{minimize: } &amp;&amp; b^T y &amp; \\\\ \\mbox{subject to: } &amp;&amp; A^T y &amp; \\geq c \\\\ &amp;&amp; y &amp; \\geq 0, \\end{aligned} \\tag{8.1} \\end{equation}\\] where \\(y = \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_m \\end{bmatrix}\\) is the vector of decision variables. We can standardize the dual to get the following linear program. \\[\\begin{equation} \\begin{aligned} \\mbox{maximize: } &amp;&amp; - b^T y &amp; \\\\ \\mbox{subject to: } &amp;&amp; -A^T y &amp; \\leq -c \\\\ &amp;&amp; y &amp; \\geq 0, \\end{aligned} \\end{equation}\\] Taking further dual we get the following linear program which is equivalent to the primal (2.3). \\[\\begin{equation} \\begin{aligned} \\mbox{minimize: } &amp;&amp; -(-c^T)^T z &amp; \\\\ \\mbox{subject to: } &amp;&amp; (-A^T)^T z &amp; \\geq -b \\\\ &amp;&amp; z &amp; \\geq 0, \\end{aligned} \\end{equation}\\] Theorem 8.1 The dual of the dual is the primal. Well denote by \\(\\zeta\\) the primal objective and by \\(\\xi\\) the dual objective. Let \\(x^*\\) denote an arbitrary primal feasible solution (not necessarily optimal) and let \\(y^*\\) denote an arbitrary dual feasible solution (not necessarily optimal). Let \\(\\zeta_\\max\\) and \\(\\xi_\\min\\) denote the optimal primal and dual solutions, if they exist. Then we have \\[\\begin{align} \\zeta_\\max = \\max_{x^*} \\zeta(x^*) \\qquad \\mbox{ and } \\qquad \\xi_\\min = \\min_{y^*} \\xi(y^*). \\end{align}\\] Theorem 8.2 (Weak Duality) For any primal feasible solution \\(x^*\\) and dual feasible solution \\(y^*\\), \\(\\zeta(x^*) \\le \\xi(y^*)\\). Hence, If both the primal and dual have optimal solutions, then \\(\\zeta_\\max \\le \\xi_\\min\\). If the primal is unbounded, then the dual is infeasible. If the duals is unbounded, then the primal is infeasible. Proof. Let \\(x^*\\) be a primal feasible solution and let \\(y^*\\) be a dual feasile solution, then \\[\\begin{align} \\zeta(x^*) &amp; = c^T x^* \\\\ &amp; = (x^*)^T c \\\\ &amp; \\le (x^*)^T A^T y^* \\\\ &amp; = (A x^*)^T y^* \\\\ &amp; \\le b^T y^* \\\\ &amp; = \\xi(y^*). \\end{align}\\] In the above derivation, were repeatedly using the feasibility of both \\(x^*\\) and \\(y^*\\). The rest of the results follow naturally. 8.1 Certificate of Optimality In the next class, well prove the following stronger theorem. Theorem 8.3 If the primal has an optimal feasible solution then so does the dual and in this case \\(\\zeta_\\max = \\xi_\\min\\). Assuming this we can find an efficient way to verify the solution to our linear program. \\(x^*\\) is the optimal primal solution and \\(y^*\\) is the optimal dual solution if and only if the following hold: \\(x^*\\) is primal feasible, \\(y^*\\) is dual feasible, \\(\\zeta(x^*) = \\xi(y^*)\\). This is called providing a Certificate of Optimality. "],["strong-duality.html", "Lecture 9 Strong Duality 9.1 Dual simplex method", " Lecture 9 Strong Duality Theorem 9.1 (Strong duality) If a standard linear program has an optimal solution, then so does its dual. Moreover, in this case, they have the same optimal objective values. Before we start with the proof of strong duality, we need to define the dual dictionary. Recall that the dictionary of the standard linear program (2.3) is given by (4.1). The dual dictionary is the dictionary of the standardized dual. More explicitly, the dual dictionary is as follows. \\[\\begin{equation} \\begin{array}{rrrrrrrrrrrr} \\mbox{maximize: } &amp; \\xi &amp; = &amp; -c_0 &amp; - &amp; b_1 y_{m+1} &amp; - &amp; \\dots &amp; - &amp; b_m y_{m + n} \\\\ \\mbox{subject to: } &amp; y_{1} &amp; = &amp; -c_1 &amp; + &amp; a_{11} y_{m+1} &amp; + &amp; \\dots &amp; + &amp; a_{m1} y_{n+m} \\\\ &amp; y_{2} &amp; = &amp; -c_2 &amp; + &amp; a_{21} y_{m+1} &amp; + &amp; \\dots &amp; + &amp; a_{m2} y_{n+m} \\\\ &amp; &amp; &amp; &amp; &amp; &amp; \\vdots &amp; &amp; \\\\ &amp; y_{m} &amp; = &amp; -c_n &amp; + &amp; a_{n1} y_{m+1} &amp; + &amp; \\dots &amp; + &amp; a_{nm} y_{n+m}, \\end{array} \\\\ y_1, \\: \\dots \\: , \\: y_{m + n} \\: \\geq \\: 0. \\tag{9.1} \\end{equation}\\] Note the unusual choice of labeling the basic and non-basic variables. This ensures that the dual dictionary (9.1) is negative transpose of the primal dictionary (4.1). The following theorem is the key ingredient in the proof of strong duality. Lemma 9.1 (Dual pivots) If we perform a pivot with \\(x_i\\) entering and \\(x_j\\) leaving on the primal dictionary and a pivot with \\(y_j\\) entering and \\(y_i\\) leaving on the dual dictionary, then the resulting dictionaries are negative transposes of each other. This lemma is proven by explicitly calculating the result of both the pivots and verifying that the results are negative transposes. The following is a simple example thatll help you see the steps of the proof. Exercise 9.1 Consider a primal-dual dictionary dictionary pair: \\[\\begin{align*} \\begin{array}{rrrrrrrrrrr} \\zeta &amp; = &amp; c_0 &amp; + &amp; c_1 x_1 &amp; + &amp; c_2 x_2 \\\\ x_3 &amp; = &amp; b_1 &amp; - &amp; a_{11} x_1 &amp; - &amp; a_{12} x_2 \\end{array} &amp;&amp; \\begin{array}{rrrrrrrrrrr} \\xi &amp; = &amp; -c_0 &amp; - &amp; b_1 y_3 \\\\ y_1 &amp; = &amp; -c_1 &amp; + &amp; a_{11} y_3\\\\ y_2 &amp; = &amp; -c_2 &amp; + &amp; a_{12} y_3 \\end{array} \\end{align*}\\] Perform a pivot with \\(x_1\\) entering and \\(x_3\\) leaving on the primal. Perform a pivot with \\(y_3\\) entering and \\(y_1\\) leaving on the dual. Verify that after the pivots the dual dictionary is still negative transpose of the primal. There is nothing special about one constraint and two variables. This proof completely generalizes to any number of equations and variables. Proof (Strong duality). Let us first consider the case when the initial primal dictionary is feasible. We run the simplex algorithm to find the optimal solution. Every time we perform a pivot \\((x_i, x_j)\\) we perform the dual pivot \\((y_j, y_i)\\) on the dual. By Lemma 9.1, the resulting primal and dual dictionaries will always be negative transposes of each other. If the primal has an optimal feasible solution, then at the end of the simplex method the final \\(b \\ge 0\\) (feasibility) and the final \\(c \\le 0\\) (optimality). But this precisely means that the dual dictionary is also optimal feasible and hence provides an optimal solution to the dual. Again because the primal and dual dictionaries stay negative transposes of each other, the dual optimal objective equals the primal optimal objective. If the initial primal dictionary is infeasible, then we can perform pivots to make it feasible (using information from the Phase I algorithm. We perform the dual pivots on the dual and then continue the proof as above. Exercise 9.2 Consider a linear program in the standard form: \\[\\begin{align*} \\begin{array}{lrrllll} \\mbox{maximize: } &amp; \\zeta &amp; = &amp; c^T x &amp; \\\\ \\mbox{subject to: } &amp; A x &amp; \\leq &amp; b \\\\ &amp; x &amp; \\geq &amp; 0. \\end{array} \\end{align*}\\] Assume that the problem has an optimal solution \\(x^*\\) with the corresponding objective \\(\\zeta_{\\max}\\). Using strong duality, show that \\[\\dfrac{\\partial \\zeta_{\\max}}{\\partial b_j} = y^*_j \\mbox{ for } 1 \\le j \\le m, \\] where \\(y^*\\) is the optimal dual solution. (Recall that this is the \\(j^{th}\\) shadow price.) 9.1 Dual simplex method It can happen that the initial primal dictionary is infeasible but the initial dual dictionary is feasible. This will be case if some \\(b_i &lt; 0\\) and all the \\(c_j \\le 0\\). In this case, we can avoid the Phase I algorithm by instead solving the dual problem. By strong duality, we can obtain the solution of the primal by simply taking the negative transpose of the final solution. "],["dual-primal-simplex-method.html", "Lecture 10 Dual-Primal Simplex Method 10.1 Dual Simplex Method 10.2 Dual-Primal Two Phase Simplex Method", " Lecture 10 Dual-Primal Simplex Method 10.1 Dual Simplex Method As we saw in the discussion on Strong Duality, the dictionary of the dual is always negative transpose of the dictionary of the primal. As such, we can always infer the dual dictionary from just the primal dictionary. More specifically, we can run the simplex algorithm to solve the dual while still using the primal dictionary. In this case, the dual simplex method becomes as follows. Find the leaving variable: Let \\(L\\) be the set of indices \\(i\\) such that \\(b_{i}\\) is negative. If \\(L\\) is empty, exit. Set \\(\\ell = \\min L\\). Find the entering variable: Let \\(E\\) be the set of indices \\(j\\) such that \\(a_{\\ell j}\\) is negative. If \\(E\\) is empty, exit. Dual linear program is unbounded, hence the primal is infeasible. Set \\(e = \\min \\left[ \\mathrm{arg}\\min_{j \\in E} \\left(\\dfrac{-c_j}{-a_{\\ell j}}\\right) \\right]\\). Pivot: Add \\(x_e\\) to the set of basic variables and remove it from the set of non-basic variables. Add \\(x_\\ell\\) to the set of non-basic variables and remove it from the set of basic variables. Rewrite the basic variables and the objective function in terms of the non-basic variables. Go back to step 1. The above dual simplex method can be used on the primal dictionary when it is dual feasible i.e.Â when all \\(c_i \\le 0\\). The goal of the algorithm is to find the optimal dual feasible solution, i.e.Â to make all the \\(b_i \\ge 0\\). By strong duality, this also gives us the optimal feasible primal solution. 10.2 Dual-Primal Two Phase Simplex Method The above algorithm provides a slightly faster way to run the 2 phase simplex method. If the initial dictionary is neither primal nor dual feasible then we need to run the Phase I simplex algorithm to find find one basic feasible solution. For this, we form an auxiliary linear program by replacing the original objective function by \\[\\begin{align} \\zeta&#39; = -x_1 -x_2 - \\dots -x_n. \\end{align}\\] By construction the auxiliary linear program is dual feasible and hence can be solved using the dual simplex method. If no solution is found, then the initial problem is also infeasible. If we find an optimal solution, then in the end we are left with a dictionary that is primal feasible but has the wrong objective function. We simply plug back the original objective function and continue solving the resulting dictionary using the Phase II (primal) simplex method. The advantage of this two phase simplex method over the one studied earlier in Lecture 4 is that at the end of Phase I we do not have to reset the auxiliary dictionary and start Phase II from scratch. "],["complimentary-slackness-general-lp.html", "Lecture 11 Complimentary Slackness, General LP 11.1 Complimentary Slackness 11.2 Dual of General Linear Programs", " Lecture 11 Complimentary Slackness, General LP 11.1 Complimentary Slackness The following theorem is sometimes useful as a test for optimality. Theorem 11.1 (Complimentary Slackness) Let \\(x\\) and \\(y\\) be basic feasible solutions for the primal and dual, respectively. Let \\(w\\) and \\(z\\) be the corresponding primal and dual slack variables, respectively. Then \\(x\\) and \\(y\\) are optimal if and only if \\[\\begin{align} z^T x = 0 &amp;&amp; \\mbox{ and } &amp;&amp; y^T w = 0. \\end{align}\\] Proof. The proofs of the two directions rely on the following algebraic properties: \\(w = b - Ax\\), \\(z = c - A^T y\\), \\(\\zeta(x) = c^T x\\), \\(\\xi(y) = y^T b\\), \\(\\zeta(x) \\le y^T A x \\le \\xi(y)\\), where the last inequalities are true by the proof of Weak Duality (Theorem 8.2). Using Strong duality and above (in)equalities, we get \\[\\begin{align} &amp;&amp; \\mbox{$x$ and $y$ are optimal solutions} \\\\ \\Leftrightarrow &amp;&amp; \\zeta(x) = y^T A x = \\xi(y) \\\\ \\Leftrightarrow &amp;&amp; \\zeta(x) - y^T A x = 0 \\mbox{ and } y^T A x - \\xi(y) = 0 \\\\ \\Leftrightarrow &amp;&amp; c^T x - y^T A x = 0 \\mbox{ and } y^T A x - y^T b = 0 \\\\ \\Leftrightarrow &amp;&amp; c^T x - y^T A x = 0 \\mbox{ and } y^T A x - y^T b = 0 \\\\ \\Leftrightarrow &amp;&amp; (c^T - y^T A) x = 0 \\mbox{ and } y^T (A x - b) = 0 \\\\ \\Leftrightarrow &amp;&amp; z^T x = 0 \\mbox{ and } -y^T w = 0. \\end{align}\\] 11.2 Dual of General Linear Programs While it is possible to standardize any linear program, it is informative to see what the dual looks like for a linear program that isnt standard. Recall from Theorem 2.2 that there are 4 types of errors a non-standard linear program could have: A linear constraint is a lower bound and has the form \\[a_{i1} x_1 + \\dots + a_{in} x_n \\geq b_i.\\] A linear constraint is an equality and has the form \\[a_{i1} x_1 + \\dots + a_{in} x_n = b_i.\\] A variable \\(x_j\\) has a negativity constraint \\(x_j \\leq 0\\). A variable \\(x_j\\) is a free variable. 11.2.1 Lower Bound and Negativity We fix the lower bound constrains by multiplying both sides by \\(-1\\) and thereby flipping the inequality: \\(-a_{i1} x_1 - \\dots - a_{in} x_n \\leq b_i.\\) One can check that the resulting dual problem is equivalent to dualizing \\(a_{i1} x_1 + \\dots + a_{in} x_n \\geq b_i\\) but requiring the dual variable \\(y_i\\) to satisfy the negativity constraint \\(y_i \\le 0\\). Thus the dual of the first type of error is the error of third type. Because the dual of the dual is the primal, the converse of this statement is also true. 11.2.2 Equality and Freeness We fix the equality constrains by replacing them with two inequalities: \\(a_{i1} x_1 + \\dots + a_{in} x_n \\leq b_i,\\) and \\(-a_{i1} x_1 - \\dots - a_{in} x_n \\leq b_i.\\) One can check that the resulting dual problem is equivalent to dualizing \\(a_{i1} x_1 + \\dots + a_{in} x_n \\geq b_i\\) but requiring the dual variable \\(y_i\\) to be free. Thus the dual of the second type of error is the error of fourth type. Because the dual of the dual is the primal, the converse of this statement is also true. To summarize, we can think of the variables in the dual as corresponding to the constraints in the primal and the variables in the primal correspond to the constraints in the dual. The precise correspondence is as follows. Primal Dual Non-negative variable Lower bound constraint Non-positive variable Upper bound constraint Free variable Equality constraint Upper bound constraint Non-positive variable Lower bound constraint Non-negative variable Equality constraint Free variable "],["tableau-method.html", "Lecture 12 Tableau method 12.1 Pivoting Example", " Lecture 12 Tableau method The tableau method is an alternate way of bookkeeping for the simplex method. It is NOT new method. The tableau method is easier to implement on paper as it reduces the pivot step to elementary row operations. Given the standard linear program (2.2) we rewrite the constraint equations in the dictionary (4.1) with all the variables (including the slack ones) on one side. \\[\\begin{equation} \\begin{array}{cccccccccc} a_{11} x_1 &amp; + &amp; a_{12} x_2 &amp; + &amp; \\dots &amp; + &amp; a_{1n} x_n &amp; + &amp; x_{n+1} &amp; = &amp; b_1 \\\\ a_{21} x_1 &amp; + &amp; a_{22} x_2 &amp; + &amp; \\dots &amp; + &amp; a_{1n} x_n &amp; + &amp; x_{n+2} &amp; = &amp; b_2 \\\\ &amp; &amp; &amp; &amp; \\vdots &amp; &amp; &amp; &amp; &amp; &amp; \\vdots \\\\ a_{m1} x_1 &amp; + &amp; a_{m2} x_2 &amp; + &amp; \\dots &amp; + &amp; a_{1n} x_n &amp; + &amp; x_{n+m} &amp; = &amp; b_m \\\\ \\end{array} \\end{equation}\\] These equations can be rewritten using the matrix notation as \\[\\begin{align} [A \\quad I_m] x = b, \\end{align}\\] where \\(I_m\\) is the identity matrix of size \\(m\\). We create the initial tableau, which is an \\((n+1) \\times (m+1)\\) matrix, using the coefficients \\(A\\), \\(b\\), and \\(c\\) as follows. \\[\\begin{align} \\begin{array}{cccccccc|c} -c_1 &amp; -c_2 &amp; \\dots &amp; -c_n &amp; 0 &amp; 0 &amp; \\dots &amp; 0 &amp; 0 \\\\ \\hline a_{11} &amp; a_{12} &amp; \\dots &amp; a_{1n} &amp; 1 &amp; 0 &amp; \\dots &amp; 0 &amp; b_1 \\\\ a_{21} &amp; a_{22} &amp; \\dots &amp; a_{2n} &amp; 0 &amp; 1 &amp; \\dots &amp; 0 &amp; b_2 \\\\ &amp; &amp; \\vdots &amp; &amp; &amp; &amp; &amp; &amp; \\vdots \\\\ a_{m1} &amp; a_{m2} &amp; \\dots &amp; a_{mn} &amp; 0 &amp; 0 &amp; \\dots &amp; 1 &amp; b_m \\\\ \\end{array} \\\\[10pt] \\mathcal{B} = \\{ x_{n+1}, \\dots, x_{n+m} \\}. \\end{align}\\] As we run the simplex method, the tableau gets updated. At each stage, the \\(j^{th}\\) column corresponds to the variable \\(x_j\\) and the \\(i^{th}\\) row corresponds to the \\(i^{th}\\) constraint in the current dictionary. Thus from a dictionary we can always construct a tableau using the following rules: The \\((0, j)\\) entry is the negative of the current coefficient \\(-c_j\\). The \\((0, m+1)\\) entry is the current objective. The \\((i, m+1)\\) entry is the current \\(b_i\\), for \\(i &gt; 0\\). The \\((i, j)\\) entry is the current \\(a_{ij}\\). It is easy to see that the converse is also true, i.e.Â from a tableau one can construct a dictionary by forming an equality constraint for each row. So a tableau contains exactly the same information as a dictionary. 12.1 Pivoting We perform the pivot with \\(x_j\\) entering and \\(x_i\\) leaving as follows: Normalize the coefficient: Divide the \\(i^{th}\\) row \\(R_i\\) by \\(a_{ij}\\) to make the coefficient 1. Clear the column: For every other \\(i&#39;\\), apply the row operation \\(R_{i&#39;} \\leftarrow R_{i&#39;} - a_{i&#39;j} R_i\\). As a result of these operations, the \\(j^{th}\\) columns becomes \\(e_{i}\\). In the language of dictionaries, this is ensuring that \\(x_i\\) is now a basic variable and can be written in terms of the non-basic variables. Example Consider Example (3.1) again. The initial tableau is: \\[\\begin{align} \\begin{array}{ccccccc|c} 1 &amp; + &amp; 1.5 &amp; + &amp; 0 &amp; + &amp; 0 &amp; 0\\\\ \\hline 1 &amp; + &amp; 2 &amp; + &amp; 1 &amp; + &amp; 0 &amp; 10 \\\\ 4 &amp; + &amp; 3 &amp; + &amp; 0 &amp; + &amp; 1 &amp; 20 \\end{array} \\\\[10pt] \\mathcal{B} = \\{3, 4\\} \\end{align}\\] At the first pivot: \\(x_1\\) enters and \\(x_4\\) leaves the set of basic variables. For this, we first divide the row \\(R_2\\) by 4. \\[\\begin{align} \\begin{array}{ccccccc|c} -1 &amp; + &amp; -1.5 &amp; + &amp; 0 &amp; + &amp; 0 &amp; 0\\\\ \\hline 1 &amp; + &amp; 2 &amp; + &amp; 1 &amp; + &amp; 0 &amp; 10 \\\\ 1 &amp; + &amp; 0.75 &amp; + &amp; 0 &amp; + &amp; 0.25 &amp; 5 \\end{array} \\\\[10pt] \\mathcal{B} = \\{3, 4\\} \\end{align}\\] And then do the elementary row operations \\(R_0 \\leftarrow R_0 + R_2\\) and \\(R_1 \\leftarrow R_1 - R_2\\) to get \\[\\begin{align} \\begin{array}{ccccccc|c} 0 &amp; + &amp; -0.75 &amp; + &amp; 0 &amp; + &amp; 0.25 &amp; 5\\\\ \\hline 0 &amp; + &amp; 1.25 &amp; + &amp; 1 &amp; + &amp; -0.25 &amp; 5 \\\\ 1 &amp; + &amp; 0.75 &amp; + &amp; 0 &amp; + &amp; 0.25 &amp; 5 \\end{array} \\\\[10pt] \\mathcal{B} = \\{1, 3\\} \\end{align}\\] At the second pivot: \\(x_2\\) enters and \\(x_3\\) leaves the set of basic variables. For this, we first divide the row \\(R_1\\) by \\(5/4\\). \\[\\begin{align} \\begin{array}{ccccccc|c} 0 &amp; + &amp; -0.75 &amp; + &amp; 0 &amp; + &amp; 0.25 &amp; 5\\\\ \\hline 0 &amp; + &amp; 1 &amp; + &amp; 0.8 &amp; + &amp; -0.2 &amp; 4 \\\\ 1 &amp; + &amp; 0.75 &amp; + &amp; 0 &amp; + &amp; 0.25 &amp; 5 \\end{array} \\\\[10pt] \\mathcal{B} = \\{1, 3\\} \\end{align}\\] And then do the elementary row operations \\(R_0 \\leftarrow R_0 + 0.75 R_1\\) and \\(R_2 \\leftarrow R_2 - 0.75 R_1\\) to get \\[\\begin{align} \\begin{array}{ccccccc|c} 0 &amp; + &amp; 0 &amp; + &amp; 0.6 &amp; + &amp; 0.1 &amp; 8\\\\ \\hline 0 &amp; + &amp; 1 &amp; + &amp; 0.8 &amp; + &amp; -0.2 &amp; 4 \\\\ 1 &amp; + &amp; 0 &amp; + &amp; -0.6 &amp; + &amp; 0.4 &amp; 2 \\end{array} \\\\[10pt] \\mathcal{B} = \\{1, 2\\} \\end{align}\\] You should compare this with the solution from Lecture 3. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
