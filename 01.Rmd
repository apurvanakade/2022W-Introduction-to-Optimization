# (PART) Part I - Linear Programming {-}

# Introduction to Linear Programming

```{r, results = 'asis', echo = FALSE}
source("R/01.R", local = knitr::knit_global())
```


Linear programming is a technique for the optimization of a linear objective function, subject to linear equality and linear inequality constraints. A *linear program* or a *linear programming problem* is a problem of the following form:

\begin{equation}
  \begin{aligned}
    \mbox{optimize: } && c_1 x_1 + \dots + c_n x_n & \\
    \mbox{subject to: } 
      && a_{11} x_1 + \dots + a_{1n} x_n & \lesseqgtr b_1 \\
      && a_{21} x_1 + \dots + a_{2n} x_n & \lesseqgtr b_2 \\
      && \vdots &  \\
      && a_{m1} x_1 + \dots + a_{mn} x_n & \lesseqgtr b_m,
  \end{aligned}
  (\#eq:intro-lp)
\end{equation}
where the symbol $\lesseqgtr$ stands for $\leq$ or $=$ or $\geq$, $a_{ij}, b_i, c_j$ are real numbers, and $x_j$ are variables.

The variables $x_1, \dots, x_n$ are called *decision variables*. The linear combination $\zeta := c_1 x_1 + \dots + c_n x_n$ is called the *objective function*. Each of the equalities/inequalities $a_{i1} x_1 + \dots + a_{in} x_n \lesseqgtr b_i$ is called a *(linear) constraint*. Our goal is to either *minimize* or *maximize* the objective function subject to the constraints.

A proposal of specific values for the decision variables is called a *solution*. A solution is said to be *feasible* if it satisfies all the constraints. A feasible solution is said to be *optimal* if $\zeta$ attains the optimal value at the solution. Thus, to solve a linear program means to *find an optimal solution* to the problem. If a problem has no feasible solutions, then the problem is called *infeasible*. If a problem has feasible solutions with arbitrarily large or arbitrary small objective values then the problem is called *unbounded*.

:::{.remark}

We do not allow strict inequalities $<$ or $>$ in a linear program as linear functions do not always achieve maxima/minima on open sets. Consider the following simple example.

```{r, results = 'asis', echo = FALSE}
ob <- new_linear_combination(10)
c1 <- new_constraint(ob, "<", 20)
c2 <- new_constraint(new_linear_combination(5), "\\geq", 0)
cat(str_math(new_linear_program(ob, list(c1, c2))))
```

On the feasible set $[0, 2)$, the function $\zeta(x_1) = x_1$ never attains absolute maxima.
Changing the inequality $<$ to $\leq$ gives us an optimal feasible solution $x_1 = 2$. When all the inequalities are either $\le$, $=$, or $\ge$, the set of feasible solutions is closed. If, in addition, the LP is bounded then the set of feasible solutions is compact. On compact sets a continuous (in particular, linear) function, always attains a maxima and a minima by a generalization of the [extreme value theorem](https://en.wikipedia.org/wiki/Extreme_value_theorem) for [higher dimensions](https://math.stackexchange.com/a/881569).

:::

## Resource allocation problem
It is useful to think of the objective function as the *profit* function, the decision variable $x_j$ as the amount of a physical quantity of type $j$, the coefficients $c_j$ as being the profit made from selling a unit quantity of type $j$, and each constraint as describing an upper bound on the production of an intermediate quantity. This is called a *resource allocation problem*.

Consider the following situation. Suppose you want to buy shares in two mutual funds, let's call them $A$ and $B$, currently priced at \$100 and \$75, respectively. Suppose you have a total of \$500 to invest. You predict that in a year you'll make $15\%$ profit on $A$ and $10\%$ profit on $B$. But there is a commission fee of 

Assuming you want to make the most profit, your optimization function becomes: